
Practical 1 Eigen Values and Eigen Vectors
Aim: Performing matrix multiplication and finding eigen vectors and eigen values using 
TensorFlow
Code: 
# importing numpy library
import numpy as np
# create numpy 2d-array
m = np.array([[1, 2],
[2, 3]])
print("Printing the Original square array:\n",m)
print()
print('***************************************')
print()
# finding eigenvalues and eigenvectors
w, v = np.linalg.eig(m)
# printing eigen values
print("Printing the Eigen values of the given square array:\n",w)
print()
# printing eigen vectors
print("Printing Right Eigen Vectors of the given square array:\n",v)
# importing numpy library
import numpy as np
# create numpy 2d-array
m = np.array([[1, 2, 3],
[2, 3, 4],
[4, 5, 6]])
print("Printing the Original square array:\n",m)
print()
print('***************************************')
print()
# finding eigenvalues and eigenvectors
w, v = np.linalg.eig(m)
# printing eigen values
print("Printing the Eigen values of the given square array:\n",w)
print()
# printing eigen vectors
print("Printing Right eigenvectors of the given square array:\n",v)
import tensorflow as tf
# Let's see how we can compute the eigen vectors and values from a matrix
e_matrix_A = tf.random.uniform([2, 2], minval=3, maxval=10, dtype=tf.float3
2, name="matrixA")
print("Matrix A: \n{}\n\n".format(e_matrix_A))
# Calculating the eigen values and vectors using tf.linalg.eigh, if you onl
y want the values you can use eigvalsh
eigen_values_A, eigen_vectors_A = tf.linalg.eigh(e_matrix_A)
print("Eigen Vectors: \n{} \n\nEigen Values: \n{}\n".format(eigen_vectors_A
, eigen_values_A))
# Let's see how we can compute the eigen vectors and values from a matrix
e_matrix_A = tf.random.uniform([3, 3], minval=3, maxval=10, dtype=tf.float3
2, name="matrixA")
print("Matrix A: \n{}\n\n".format(e_matrix_A))
# Calculating the eigen values and vectors using tf.linalg.eigh, if you onl
y want the values you can use eigvalsh
eigen_values_A, eigen_vectors_A = tf.linalg.eigh(e_matrix_A)
print("Eigen Vectors: \n{} \n\nEigen Values: \n{}\n".format(eigen_vectors_A
, eigen_values_A))
Output: 
 
Practical 2 XOR Using Neural Networks
Aim: Solving XOR problem using deep feed forward network
Code: 
# importing Python library 
import numpy as np 
# define Unit Step Function 
def unitStep(v): 
 if v >= 0: 
 return 1
 else: 
 return 0
# design Perceptron Model 
def perceptronModel(x, w, b): 
 v = np.dot(w, x) + b 
 y = unitStep(v) 
 return y
# NOT Logic Function 
# wNOT = -1, bNOT = 0.5 
def NOT_logicFunction(x): 
 wNOT = -1
 bNOT = 0.5
 return perceptronModel(x, wNOT, bNOT)
# AND Logic Function 
# here w1 = wAND1 = 1, 
# w2 = wAND2 = 1, bAND = -1.5 
def AND_logicFunction(x): 
 w = np.array([1, 1]) 
 bAND = -1.5
 return perceptronModel(x, w, bAND) 
 
# OR Logic Function 
# w1 = 1, w2 = 1, bOR = -0.5 
def OR_logicFunction(x): 
 w = np.array([1, 1]) 
 bOR = -0.5
 return perceptronModel(x, w, bOR)
# XOR Logic Function 
# with AND, OR and NOT 
# function calls in sequence 
def XOR_logicFunction(x):
 y1 = AND_logicFunction(x)
 y2 = OR_logicFunction(x)
 y3 = NOT_logicFunction(y1)
 final_x = np.array([y2, y3])
 finalOutput = AND_logicFunction(final_x)
 y3 = NOT_logicFunction(y1)
 return finalOutput
# testing the Perceptron Model 
test1 = np.array([0, 1]) 
test2 = np.array([1, 1]) 
test3 = np.array([0, 0]) 
test4 = np.array([1, 0])
print("XOR({}, {}) = {}".format(0, 1, XOR_logicFunction(test1)))
print("XOR({}, {}) = {}".format(1, 1, XOR_logicFunction(test2)))
print("XOR({}, {}) = {}".format(0, 0, XOR_logicFunction(test3)))
print("XOR({}, {}) = {}".format(1, 0, XOR_logicFunction(test4)))
OutPut: 
Practical 3 Binary Classification Using Neural Networks
Aim: Practical to Implement deep neural network for performing binary classification 
task.
Code: 
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
# load dataset
dataframe = pd.read_csv("/content/sonar.all-data", header=None)
dataset = dataframe.values
# split into input (X) and output (Y) variables
X = dataset[:,0:60].astype(float)
Y = dataset[:,60]
# encode class values as integers
encoder = LabelEncoder()
encoder.fit(Y)
encoded_Y = encoder.transform(Y)
# baseline model
def create_baseline():
# create model
model = Sequential()
model.add(Dense(60, input_dim=60, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', 
metrics=['accuracy'])
return model
# evaluate model with standardized dataset
estimator = KerasClassifier(build_fn=create_baseline, epochs=100, 
batch_size=5, verbose=0)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(estimator, X, encoded_Y, cv=kfold)
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, 
results.std()*100))
#Re-Run The Baseline Model With Data Preparation
# evaluate baseline model with standardized dataset
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=
100, batch_size=5, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)
print("Standardized: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*
100))
# smaller model
def create_smaller():
# create model
model = Sequential()
model.add(Dense(30, input_dim=60, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', 
metrics=['accuracy'])
return model
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, 
epochs=100, batch_size=5, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)
print("Smaller: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))
# larger model
def create_larger():
# create model
model = Sequential()
model.add(Dense(60, input_dim=60, activation='relu'))
model.add(Dense(30, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', 
metrics=['accuracy'])
return model
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasClassifier(build_fn=create_larger, 
epochs=100, batch_size=5, verbose=0)))
pipeline = Pipeline(estimators)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)
print("Larger: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))
 
OutPut: 
Baseline: 81.79% (9.69%)
Standardized: 87.98% (9.50%)
Smaller: 82.14% (5.53%)
Larger: 87.05% (6.74%)


Practical 4 Breast Cancer Classification Using Neural 
Networks
Aim: Practical to perform Breast Cancer Classification with a simple Neural Network 
(NN). 
Code: 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn.datasets
from sklearn.model_selection import train_test_split
# loading the data from sklearn
breast_cancer_dataset = sklearn.datasets.load_breast_cancer()
print(breast_cancer_dataset)
# loading the data to a data frame
data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_data
set.feature_names)
# print the first 5 rows of the dataframe
data_frame.head()
# adding the 'target' column to the data frame
data_frame['label'] = breast_cancer_dataset.target
# print last 5 rows of the dataframe
data_frame.tail()
# number of rows and columns in the dataset
data_frame.shape
# getting some information about the data
data_frame.info()
# checking for missing values
data_frame.isnull().sum()
# statistical measures about the data
data_frame.describe()
# checking the distribution of Target Varibale
data_frame['label'].value_counts()
data_frame.groupby('label').mean()
#Separating the features and target
X = data_frame.drop(columns='label', axis=1)
Y = data_frame['label']
print(X)
print(Y)
#Splitting the data into training data & Testing data
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
print(X.shape, X_train.shape, X_test.shape)
#Standardize the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)
# importing tensorflow and Keras
import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras
# setting up the layers of Neural Network
model = keras.Sequential([
keras.layers.Flatten(input_shape=(30,)),
keras.layers.Dense(20, activation='relu'),
keras.layers.Dense(2, activation='sigmoid')
])
# compiling the Neural Network
model.compile(optimizer='adam',
loss='sparse_categorical_crossentropy',
metrics=['accuracy'])
# training the Meural Network
history = model.fit(X_train_std, Y_train, validation_split=0.1, epochs=10)
#Visualizing accuracy and loss
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training data', 'validation data'], loc = 'lower right')
#Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['training data', 'validation data'], loc = 'upper right')
#Accuracy of the model on test data
loss, accuracy = model.evaluate(X_test_std, Y_test)
print(accuracy)
print(X_test_std.shape)
print(X_test_std[0])
Y_pred = model.predict(X_test_std)
print(Y_pred.shape)
print(Y_pred[0])
print(X_test_std)
print(Y_pred)
# argmax function
my_list = [0.25, 0.56]
index_of_max_value = np.argmax(my_list)
print(my_list)
print(index_of_max_value)
# converting the prediction probability to class labels
Y_pred_labels = [np.argmax(i) for i in Y_pred]
print(Y_pred_labels)
#Building the predictive system
input_data = (11.76,21.6,74.72,427.9,0.08637,0.04966,0.01657,0.01115,0.1495,0.05888,
0.4062,1.21,2.635,28.47,0.005857,0.009758,0.01168,0.007445,0.02406,0.001769,12.98,
25.72,82.98,516.5,0.1085,0.08615,0.05523,0.03715,0.2433,0.06563)
# change the input_data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)
# reshape the numpy array as we are predicting for one data point
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)
# standardizing the input data
input_data_std = scaler.transform(input_data_reshaped)
prediction = model.predict(input_data_std)
print(prediction)
prediction_label = [np.argmax(prediction)]
print(prediction_label)
if(prediction_label[0] == 0):
print('The tumor is Malignant')
else:
print('The tumor is Benign')
OutPut: 


Practical 5 Number Prediction Using CNN
Aim: Implementation of convolutional neural network to predict numbers from 
number images.
Code: 
import tensorflow as tf
 
mnist = tf.keras.datasets.mnist
 
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train.shape
 
y_train.shape
 
X_test.shape
 
y_test.shape
 
import matplotlib.pyplot as plt
plt.imshow(X_train[2])
plt.show()
plt.imshow(X_train[2], cmap=plt.cm.binary)
X_train[2]
 
#Normalizing the data
X_train = tf.keras.utils.normalize(X_train, axis=1) 
X_test = tf.keras.utils.normalize(X_test, axis=1)
plt.imshow(X_train[2], cmap=plt.cm.binary)
print(X_train[2])
import tensorflow as tf
import tensorflow.keras.layers as KL
import tensorflow.keras.models as KM
## Model
inputs = KL.Input(shape=(28, 28, 1))
c = KL.Conv2D(32, (3, 3), padding="valid", activation=tf.nn.relu)(inputs)
m = KL.MaxPool2D((2, 2), (2, 2))(c)
d = KL.Dropout(0.5)(m)
c = KL.Conv2D(64, (3, 3), padding="valid", activation=tf.nn.relu)(d)
m = KL.MaxPool2D((2, 2), (2, 2))(c)
d = KL.Dropout(0.5)(m)
c = KL.Conv2D(128, (3, 3), padding="valid", activation=tf.nn.relu)(d)
f = KL.Flatten()(c)
outputs = KL.Dense(10, activation=tf.nn.softmax)(f)
model = KM.Model(inputs, outputs)
model.summary()
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", 
metrics=["accuracy"])
model.fit(X_train, y_train, epochs=5)
test_loss, test_acc = model.evaluate(X_test, y_test)
print("Test Loss: {0} - Test Acc: {1}".format(test_loss, test_acc))
OutPut: 



Practical 6 Implementing Recurrent Neural Network on CiFar_10 dataset.

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical

# Load and preprocess the CIFAR-10 dataset
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()
train_images = train_images.astype('float32') / 255
test_images = test_images.astype('float32') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# Create the CNN model
cnn_model = models.Sequential()
cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
cnn_model.add(layers.MaxPooling2D((2, 2)))
cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))
cnn_model.add(layers.MaxPooling2D((2, 2)))
cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))
cnn_model.add(layers.Flatten())
cnn_model.add(layers.Dense(64, activation='relu'))
cnn_model.add(layers.Dense(10, activation='softmax'))

# Compile the CNN model
cnn_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

# Train the CNN model
cnn_history = cnn_model.fit(train_images, train_labels, epochs=10, batch_size=64,
                            validation_data=(test_images, test_labels))

# Evaluate the CNN model
test_loss, test_acc = cnn_model.evaluate(test_images, test_labels)
print(f'CNN Test Accuracy: {test_acc}')



# Import necessary libraries for RNN
from tensorflow.keras.layers import LSTM, Embedding, Dense

# Load and preprocess the CIFAR-10 dataset (flatten the images for RNN)
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()
train_images = train_images.reshape((50000, 32 * 32 * 3))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 32 * 32 * 3))
test_images = test_images.astype('float32') / 255
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)


# Create the RNN model
rnn_model = models.Sequential()
rnn_model.add(Embedding(input_dim=32 * 32 * 3, output_dim=128))
rnn_model.add(LSTM(64))
rnn_model.add(Dense(10, activation='softmax'))

# Compile the RNN model
rnn_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])


# Train the RNN model
rnn_history = rnn_model.fit(train_images, train_labels, epochs=10, batch_size=64,
                            validation_data=(test_images, test_labels))

# Evaluate the RNN model
test_loss, test_acc = rnn_model.evaluate(test_images, test_labels)
print(f'RNN Test Accuracy: {test_acc}')




Practica 7 : Movie Review Text classification using LSTM.
import numpy as np
from keras.models import Sequential
from keras.preprocessing import sequence
from keras.layers import Dropout
from keras.layers import Dense, Embedding, LSTM, Bidirectional
from keras.datasets import imdb
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 10000)
max_len = 200
x_train = sequence.pad_sequences(x_train, maxlen=max_len)
x_test = sequence.pad_sequences(x_test, maxlen=max_len)
y_train = np.array(y_train)
y_test = np.array(y_test)
x_train.shape, y_train.shape
x_test.shape, y_test.shape
n_unique_words = 10000

model = Sequential()
model.add(Embedding(n_unique_words, 128, input_length = max_len))
model.add(Bidirectional(LSTM(64)))
model.add(Dropout(0.5))
model.add(Dense(1, activation = 'sigmoid'))
model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

batch_size = 250

history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs = 12,
                    validation_data = [x_test, y_test])
print(history.history['loss'])
print(history.history['accuracy'])

from matplotlib import pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['accuracy'])
plt.title("Model Loss vs Accuracy")
plt.xlabel("Epoch")
plt.legend(['loss', 'accuracy'], loc = "upper right")
plt.show()


Practical 8 :Implementing GANS on MNIST Fashion Dataset

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input
from tensorflow.keras.optimizers import Adam

# Load Fashion MNIST dataset
(x_train, _), (_,_) = fashion_mnist.load_data()

# Normalize the Image
x_train = x_train / 127.5-1.0
x_train = np.expand_dims(x_train, axis = 3)

# Define Dimensions of the noise vector
latent_dim = 100

# Generator Model
generator = Sequential([
    Dense(128 * 7 * 7, input_dim = latent_dim),
    LeakyReLU(0.2),
    Reshape((7,7,128)),
    BatchNormalization(),
    Flatten(),
    Dense(128 * 7 * 7),
    LeakyReLU(0.2),
    Reshape((7,7,128)),
    BatchNormalization(),
    Flatten(),
    Dense(28*28, activation = 'tanh'),
    Reshape((28,28,1))
])


# Discriminator Model
discriminator = Sequential([
    Flatten(input_shape=(28,28,1)),
    Dense(128),
    LeakyReLU(0.2),
    Dense(1,activation = 'sigmoid')
])

# Compile the discriminator
discriminator.compile(loss = 'binary_crossentropy',
                      optimizer = Adam(lr = 0.0002, beta_1 = 0.5),
                      metrics = ['accuracy'])


# Combine the generator and discriminator into a single model
discriminator.trainable = False
gan_input = Input(shape=(latent_dim,))
generated_image = generator(gan_input)
gan_output = discriminator(generated_image)
gan = Model(gan_input, gan_output)
gan.compile(loss="binary_crossentropy",
            optimizer = Adam(lr=0.0002, beta_1 = 0.5))


# Training the GAN

epochs = 1000
batch_size = 128

for epoch in range(epochs):
  # Train the Discriminator
  idx = np.random.randint(0, x_train.shape[0], batch_size)
  real_images = x_train[idx]
  noise = np.random.normal(0,1,(batch_size, latent_dim))
  fake_images = generator.predict(noise)
  real_labels = np.ones((batch_size, 1))
  fake_labels = np.zeros((batch_size, 1))
  d_loss_real = discriminator.train_on_batch(real_images, real_labels)
  d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)
  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

  # Train generator
  noise = np.random.normal(0,1, (batch_size, latent_dim))
  fake_labels = np.ones((batch_size, 1))
  g_loss = gan.train_on_batch

  # Print Progress
  if epoch % 100 == 0:
    print(f'Epoch {epoch}/{epochs} | Discriminator Loss: {d_loss[0]} | Generator Loss: {g_loss}')

# Generate images
rows, cols = 5, 5
noise = np.random.normal(0, 1, (rows * cols, latent_dim))
generated_images = generator.predict(noise)

# Plot generated images
plt.figure(figsize=(10, 10))
for i in range(rows * cols):
    plt.subplot(rows, cols, i + 1)
    plt.imshow((generated_images[i].reshape(28, 28) + 1) / 2, cmap='gray')
    plt.axis('off')
plt.tight_layout()
plt.show()



